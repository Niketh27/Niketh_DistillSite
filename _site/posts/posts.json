[
  {
    "path": "posts/2021-04-14-kju-trump/",
    "title": "Do you look more like Kim Jong Un or Donald Trump?",
    "description": "A Deep Learning Solution to the Popular Dilemna.",
    "author": [
      {
        "name": "Niketh Gamage",
        "url": {}
      }
    ],
    "date": "2021-04-14",
    "categories": [],
    "contents": "\r\nEver sit there relaxing after work and wondered “Do I look more like Kim Jong Un or Donald Trump?”. Now you can find the definitive answer.\r\nClick here and upload a picture of your face to find out. This might take about a minute to setup the model but I am in the process of deploying the application at a permanent home.\r\nThis model uses a Convolutional Neural Network (CNN) and was developed with the help of the fastaiv2 package.\r\n\r\n\r\n\r\n",
    "preview": "posts/2021-04-14-kju-trump/kju-trump-preview.jpg",
    "last_modified": "2021-04-14T14:42:25-05:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-04-06-lendingclubarticle/",
    "title": "Lending Club Model",
    "description": "A Loan Payback Prediction Model with lasso, random forest and knn.",
    "author": [
      {
        "name": "Niketh Gamage",
        "url": {}
      }
    ],
    "date": "2021-04-06",
    "categories": [],
    "contents": "\r\n\r\n\r\n# SEE modeldata package for new datasets\r\nlibrary(tidyverse)         # for graphing and data cleaning\r\nlibrary(tidymodels)        # for modeling\r\nlibrary(stacks)            # for stacking models\r\nlibrary(naniar)            # for examining missing values (NAs)\r\nlibrary(lubridate)         # for date manipulation\r\nlibrary(moderndive)        # for King County housing data\r\nlibrary(vip)               # for variable importance plots\r\nlibrary(DALEX)             # for model interpretation  \r\nlibrary(DALEXtra)          # for extension of DALEX\r\nlibrary(patchwork)         # for combining plots nicely\r\ntheme_set(theme_minimal()) # for theming\r\n\r\nlibrary(ranger) # for random forest model\r\nlibrary(kknn)   #for knn model\r\nlibrary(ROSE)  #for ROC curve\r\n\r\n\r\n\r\n\r\n\r\ndata(\"lending_club\")\r\n\r\n\r\n\r\nModeling\r\nWe will be using the lending_club dataset, which is available in the ‘modeldata’ library in the ‘tidymodels’ package, to predict the variable Class which shows if the loan is fully paid back/being paid back (category: good) or if it is defaulted/late(category: bad).\r\nWe will try to build 3 types of models - lasso, random forest and knn - and make a final optimized model that combines all of this information.\r\nSome data exploration and checking the distributions of the variables.\r\n\r\n\r\nlending_club \r\n\r\n\r\n# A tibble: 9,857 x 23\r\n   funded_amnt term    int_rate sub_grade addr_state verification_sta~\r\n         <int> <fct>      <dbl> <fct>     <fct>      <fct>            \r\n 1       16100 term_36    14.0  C4        CT         Not_Verified     \r\n 2       32000 term_60    12.0  C1        MN         Verified         \r\n 3       10000 term_36    16.3  D1        OH         Source_Verified  \r\n 4       16800 term_60    13.7  C3        NV         Verified         \r\n 5        3500 term_36     7.39 A4        CA         Source_Verified  \r\n 6       10000 term_36    11.5  B5        TX         Source_Verified  \r\n 7       11000 term_36     5.32 A1        KY         Not_Verified     \r\n 8       15000 term_36     9.16 B2        MO         Not_Verified     \r\n 9        6000 term_36     9.8  B3        NY         Source_Verified  \r\n10       20000 term_60    13.0  C2        GA         Not_Verified     \r\n# ... with 9,847 more rows, and 17 more variables: annual_inc <dbl>,\r\n#   emp_length <fct>, delinq_2yrs <int>, inq_last_6mths <int>,\r\n#   revol_util <dbl>, acc_now_delinq <int>, open_il_6m <int>,\r\n#   open_il_12m <int>, open_il_24m <int>, total_bal_il <int>,\r\n#   all_util <int>, inq_fi <int>, inq_last_12m <int>,\r\n#   delinq_amnt <int>, num_il_tl <int>,\r\n#   total_il_high_credit_limit <int>, Class <fct>\r\n\r\n\r\n\r\n# numeric variables\r\n\r\nlending_club %>% \r\n  select(where(is.numeric)) %>% \r\n  pivot_longer(cols = everything(),\r\n               names_to = \"variable\", \r\n               values_to = \"value\") %>% \r\n  ggplot(aes(x = value)) +\r\n  geom_histogram(bins = 30) +\r\n  facet_wrap(vars(variable), \r\n             scales = \"free\")\r\n\r\n\r\n\r\n\r\n\r\n\r\n# categorical variables\r\n\r\nlending_club %>% \r\n  select(where(is.factor)) %>% \r\n  pivot_longer(cols = everything(),\r\n               names_to = \"variable\", \r\n               values_to = \"value\") %>% \r\n  ggplot(aes(x = value)) +\r\n  geom_bar() +\r\n  facet_wrap(vars(variable), \r\n             scales = \"free\", \r\n             nrow = 2)\r\n\r\n\r\n\r\n\r\nWe do some data cleaning steps to get rid of variables that are redundant/ identical to the chosen response variable ‘Class’.\r\n\r\n\r\n#get rid of zero or near zero variance variables\r\nlending_club2 <- lending_club %>% \r\n  na.omit() %>% \r\n  select(-delinq_amnt) %>% \r\n  select(-acc_now_delinq)\r\n\r\nlending_club\r\n\r\n\r\n# A tibble: 9,857 x 23\r\n   funded_amnt term    int_rate sub_grade addr_state verification_sta~\r\n         <int> <fct>      <dbl> <fct>     <fct>      <fct>            \r\n 1       16100 term_36    14.0  C4        CT         Not_Verified     \r\n 2       32000 term_60    12.0  C1        MN         Verified         \r\n 3       10000 term_36    16.3  D1        OH         Source_Verified  \r\n 4       16800 term_60    13.7  C3        NV         Verified         \r\n 5        3500 term_36     7.39 A4        CA         Source_Verified  \r\n 6       10000 term_36    11.5  B5        TX         Source_Verified  \r\n 7       11000 term_36     5.32 A1        KY         Not_Verified     \r\n 8       15000 term_36     9.16 B2        MO         Not_Verified     \r\n 9        6000 term_36     9.8  B3        NY         Source_Verified  \r\n10       20000 term_60    13.0  C2        GA         Not_Verified     \r\n# ... with 9,847 more rows, and 17 more variables: annual_inc <dbl>,\r\n#   emp_length <fct>, delinq_2yrs <int>, inq_last_6mths <int>,\r\n#   revol_util <dbl>, acc_now_delinq <int>, open_il_6m <int>,\r\n#   open_il_12m <int>, open_il_24m <int>, total_bal_il <int>,\r\n#   all_util <int>, inq_fi <int>, inq_last_12m <int>,\r\n#   delinq_amnt <int>, num_il_tl <int>,\r\n#   total_il_high_credit_limit <int>, Class <fct>\r\n\r\nlending_club2\r\n\r\n\r\n# A tibble: 9,857 x 21\r\n   funded_amnt term    int_rate sub_grade addr_state verification_sta~\r\n         <int> <fct>      <dbl> <fct>     <fct>      <fct>            \r\n 1       16100 term_36    14.0  C4        CT         Not_Verified     \r\n 2       32000 term_60    12.0  C1        MN         Verified         \r\n 3       10000 term_36    16.3  D1        OH         Source_Verified  \r\n 4       16800 term_60    13.7  C3        NV         Verified         \r\n 5        3500 term_36     7.39 A4        CA         Source_Verified  \r\n 6       10000 term_36    11.5  B5        TX         Source_Verified  \r\n 7       11000 term_36     5.32 A1        KY         Not_Verified     \r\n 8       15000 term_36     9.16 B2        MO         Not_Verified     \r\n 9        6000 term_36     9.8  B3        NY         Source_Verified  \r\n10       20000 term_60    13.0  C2        GA         Not_Verified     \r\n# ... with 9,847 more rows, and 15 more variables: annual_inc <dbl>,\r\n#   emp_length <fct>, delinq_2yrs <int>, inq_last_6mths <int>,\r\n#   revol_util <dbl>, open_il_6m <int>, open_il_12m <int>,\r\n#   open_il_24m <int>, total_bal_il <int>, all_util <int>,\r\n#   inq_fi <int>, inq_last_12m <int>, num_il_tl <int>,\r\n#   total_il_high_credit_limit <int>, Class <fct>\r\n\r\nWe saw earlier from the distribution of Class that there is a lot more good rows than bad. So, we resample with replacement some bad cases and add them to our dataset so that the good cases don’t overwhelm our classification model into predicting good all the time.\r\n\r\n\r\ncreate_more_bad <- lending_club2 %>% \r\n  filter(Class == \"bad\") %>% \r\n  sample_n(size = 3000, replace = TRUE)\r\n\r\nlending_club_mod <- lending_club2 %>% \r\n  bind_rows(create_more_bad)\r\n\r\n\r\n\r\nThen we split the data into training and testing set.\r\n\r\n\r\nset.seed(494) # for reproducibility\r\n\r\nlending_split <- initial_split(lending_club_mod, prop = 0.75)\r\n\r\nlending_training <- training(lending_split)\r\nlending_testing <- testing(lending_split)\r\n\r\n\r\n\r\nThen we create the recipe and pre-process the data to make it ready to build our first model: lasso.\r\n\r\n\r\nlending_recipe <- recipe(Class ~ . , data = lending_training) %>% \r\n  # making all integer variables are numeric\r\n  step_mutate_at(all_numeric(), fn = ~as.numeric(.)) %>% \r\n  \r\n   # making categorical variables dummy variables\r\n  step_dummy(all_nominal(),-all_outcomes()) %>% \r\n\r\n  #quantitative variables are normalized\r\n  step_normalize(all_predictors(), \r\n                 -all_nominal(),\r\n                 -has_role(match = 'evaluative'))  \r\n\r\n\r\n\r\nChecking if everything looks ok and normalized:\r\n\r\n\r\nlending_recipe %>% \r\n  prep(lending_training) %>% \r\n  juice()\r\n\r\n\r\n# A tibble: 9,643 x 113\r\n   funded_amnt int_rate annual_inc delinq_2yrs inq_last_6mths\r\n         <dbl>    <dbl>      <dbl>       <dbl>          <dbl>\r\n 1      0.0224   0.0818     -0.861      -0.357         -0.708\r\n 2      1.80    -0.299      -0.143      -0.357         -0.708\r\n 3     -0.658    0.520      -0.143      -0.357          1.45 \r\n 4      0.100    0.0208      0.419      -0.357         -0.708\r\n 5     -1.38    -1.18       -0.568      -0.357         -0.708\r\n 6     -0.658   -0.398      -0.919      -0.357         -0.708\r\n 7     -0.547   -1.57       -0.279      -0.357         -0.708\r\n 8     -0.100   -0.838       2.11        1.80          -0.708\r\n 9     -1.10    -0.717       0.187      -0.357          1.45 \r\n10      0.457   -0.109      -0.609       0.723         -0.708\r\n# ... with 9,633 more rows, and 108 more variables: revol_util <dbl>,\r\n#   open_il_6m <dbl>, open_il_12m <dbl>, open_il_24m <dbl>,\r\n#   total_bal_il <dbl>, all_util <dbl>, inq_fi <dbl>,\r\n#   inq_last_12m <dbl>, num_il_tl <dbl>,\r\n#   total_il_high_credit_limit <dbl>, Class <fct>,\r\n#   term_term_60 <dbl>, sub_grade_A2 <dbl>, sub_grade_A3 <dbl>,\r\n#   sub_grade_A4 <dbl>, sub_grade_A5 <dbl>, sub_grade_B1 <dbl>,\r\n#   sub_grade_B2 <dbl>, sub_grade_B3 <dbl>, sub_grade_B4 <dbl>,\r\n#   sub_grade_B5 <dbl>, sub_grade_C1 <dbl>, sub_grade_C2 <dbl>,\r\n#   sub_grade_C3 <dbl>, sub_grade_C4 <dbl>, sub_grade_C5 <dbl>,\r\n#   sub_grade_D1 <dbl>, sub_grade_D2 <dbl>, sub_grade_D3 <dbl>,\r\n#   sub_grade_D4 <dbl>, sub_grade_D5 <dbl>, sub_grade_E1 <dbl>,\r\n#   sub_grade_E2 <dbl>, sub_grade_E3 <dbl>, sub_grade_E4 <dbl>,\r\n#   sub_grade_E5 <dbl>, sub_grade_F1 <dbl>, sub_grade_F2 <dbl>,\r\n#   sub_grade_F3 <dbl>, sub_grade_F4 <dbl>, sub_grade_F5 <dbl>,\r\n#   sub_grade_G1 <dbl>, sub_grade_G2 <dbl>, sub_grade_G3 <dbl>,\r\n#   sub_grade_G4 <dbl>, sub_grade_G5 <dbl>, addr_state_AL <dbl>,\r\n#   addr_state_AR <dbl>, addr_state_AZ <dbl>, addr_state_CA <dbl>,\r\n#   addr_state_CO <dbl>, addr_state_CT <dbl>, addr_state_DC <dbl>,\r\n#   addr_state_DE <dbl>, addr_state_FL <dbl>, addr_state_GA <dbl>,\r\n#   addr_state_HI <dbl>, addr_state_ID <dbl>, addr_state_IL <dbl>,\r\n#   addr_state_IN <dbl>, addr_state_KS <dbl>, addr_state_KY <dbl>,\r\n#   addr_state_LA <dbl>, addr_state_MA <dbl>, addr_state_MD <dbl>,\r\n#   addr_state_ME <dbl>, addr_state_MI <dbl>, addr_state_MN <dbl>,\r\n#   addr_state_MO <dbl>, addr_state_MS <dbl>, addr_state_MT <dbl>,\r\n#   addr_state_NC <dbl>, addr_state_ND <dbl>, addr_state_NE <dbl>,\r\n#   addr_state_NH <dbl>, addr_state_NJ <dbl>, addr_state_NM <dbl>,\r\n#   addr_state_NV <dbl>, addr_state_NY <dbl>, addr_state_OH <dbl>,\r\n#   addr_state_OK <dbl>, addr_state_OR <dbl>, addr_state_PA <dbl>,\r\n#   addr_state_RI <dbl>, addr_state_SC <dbl>, addr_state_SD <dbl>,\r\n#   addr_state_TN <dbl>, addr_state_TX <dbl>, addr_state_UT <dbl>,\r\n#   addr_state_VA <dbl>, addr_state_VT <dbl>, addr_state_WA <dbl>,\r\n#   addr_state_WI <dbl>, addr_state_WV <dbl>, addr_state_WY <dbl>,\r\n#   verification_status_Source_Verified <dbl>,\r\n#   verification_status_Verified <dbl>, emp_length_emp_1 <dbl>,\r\n#   emp_length_emp_ge_10 <dbl>, emp_length_emp_2 <dbl>, ...\r\n\r\nThen we set up the lasso model and workflow and set the penalty parameter to tune().\r\n\r\n\r\n#define lasso model\r\nlending_lasso_mod <- \r\n  logistic_reg(penalty = tune(), mixture = 1) %>% \r\n  set_engine(\"glmnet\") %>% \r\n  set_mode(\"classification\")\r\n\r\n\r\n\r\n\r\n\r\n# create workflow\r\nlending_lasso_wf <- \r\n  workflow() %>% \r\n  add_recipe(lending_recipe) %>% \r\n  add_model(lending_lasso_mod)\r\n\r\n\r\n\r\nSet up the model tuning for the penalty parameter. Be sure to add the control_stack_grid() for the control argument so we can use these results later when we stack. Find the accuracy and area under the roc curve for the model with the best tuning parameter. Use 5-fold cv.\r\nSetting up model tuning for the penalty parameter with 5-fold cross validation using the training dataset\r\n\r\n\r\nset.seed(494) #for reproducible 5-fold\r\n\r\nlending_cv <- vfold_cv(lending_training, v = 5)\r\n\r\npenalty_grid <- grid_regular(penalty(),\r\n                             levels = 10)\r\n\r\naccuracy_met <- metric_set(accuracy)\r\n\r\n# tune the model \r\nlending_lasso_tune <- \r\n  lending_lasso_wf %>% \r\n  tune_grid(\r\n    resamples = lending_cv,\r\n    grid = penalty_grid,\r\n    control = control_stack_grid()\r\n#    metrics = accuracy_met\r\n    )\r\n\r\n\r\n\r\nFinding the best tuning parameter and finalizing the model.\r\n\r\n\r\n# Best tuning parameter by smallest rmse\r\nbest_param <- lending_lasso_tune %>% \r\n  select_best(metric = \"accuracy\")\r\n\r\nlending_lasso_final_wf <- lending_lasso_wf %>% \r\n  finalize_workflow(best_param)\r\n\r\nlending_lasso_final_mod <- lending_lasso_final_wf %>% \r\n  fit(data = lending_training)\r\n\r\n\r\n\r\nLet’s take a look at the model estimates for our predictors\r\n\r\n\r\nlending_lasso_final_mod %>% \r\n  pull_workflow_fit() %>% \r\n  tidy() \r\n\r\n\r\n# A tibble: 113 x 3\r\n   term           estimate  penalty\r\n   <chr>             <dbl>    <dbl>\r\n 1 (Intercept)     1.29    0.000464\r\n 2 funded_amnt    -0.0172  0.000464\r\n 3 int_rate       -0.989   0.000464\r\n 4 annual_inc     -0.141   0.000464\r\n 5 delinq_2yrs     0.0133  0.000464\r\n 6 inq_last_6mths -0.130   0.000464\r\n 7 revol_util      0.0701  0.000464\r\n 8 open_il_6m     -0.104   0.000464\r\n 9 open_il_12m    -0.254   0.000464\r\n10 open_il_24m     0.00632 0.000464\r\n# ... with 103 more rows\r\n\r\nThen we fit the model with the testing data and check the metrics.\r\n\r\n\r\n# Fit model with best tuning parameter(s) to training data and apply to test data\r\nlending_lasso_test <- lending_lasso_final_wf %>% \r\n  last_fit(lending_split)\r\n\r\n# Metrics for model applied to test data\r\nlending_lasso_test %>% \r\n  collect_metrics()\r\n\r\n\r\n# A tibble: 2 x 4\r\n  .metric  .estimator .estimate .config             \r\n  <chr>    <chr>          <dbl> <chr>               \r\n1 accuracy binary         0.760 Preprocessor1_Model1\r\n2 roc_auc  binary         0.779 Preprocessor1_Model1\r\n\r\nNot amazing but not too bad either. Now let’s move on to the random forest model.\r\nSetting up the recipe and the pre-processing steps to build a random forest model.\r\n\r\n\r\n# set up recipe and transformation steps and roles\r\nlendingrf_recipe <- \r\n  recipe(formula = Class ~ ., \r\n         data = lending_training) %>% \r\n  step_mutate_at(all_numeric(), \r\n            fn= ~as.numeric(.)) \r\n\r\n\r\n\r\nSetting up the random forest model and workflow and we tune over min_n and mtry\r\n\r\n\r\n#define model\r\nlendingrf_spec <- \r\n  rand_forest(mtry = tune(), \r\n              min_n = tune(), \r\n              trees = 100) %>% \r\n  set_mode(\"classification\") %>% \r\n  set_engine(\"ranger\")\r\n\r\n#create workflow\r\nlendingrf_wf <- \r\n  workflow() %>% \r\n  add_recipe(lendingrf_recipe) %>% \r\n  add_model(lendingrf_spec) \r\n\r\n\r\n\r\nTuning the model using 5 fold cross-validation\r\n\r\n\r\n#fit the model\r\nset.seed(494) # for reproducibility - random sampling in random forest choosing number of variables\r\n\r\n\r\nrfpenalty_grid <- grid_regular(finalize(mtry(), lending_training %>% select(-Class)), min_n(), levels = 3)\r\n\r\n\r\n\r\nlendingrf_tune <-\r\n  lendingrf_wf %>% \r\n  tune_grid(\r\n    resamples = lending_cv,\r\n    control = control_stack_grid(),\r\n    grid = rfpenalty_grid)\r\n\r\n\r\n\r\nFinalizing the model and fitting it to the testing data\r\n\r\n\r\n# Best tuning parameter by smallest rmse\r\nbestrf_param <- lendingrf_tune %>% \r\n  select_best(metric = \"accuracy\")\r\n\r\nlendingrf_final_wf <- lendingrf_wf %>% \r\n  finalize_workflow(bestrf_param)\r\n\r\n\r\nlendingrf_final_mod<- lendingrf_final_wf %>% \r\n  fit(lending_training)\r\n  \r\nlendingrf_last_fit <- lendingrf_final_wf %>% \r\n  last_fit(lending_split) \r\n\r\n\r\n\r\nMetrics for the finalized random forest model\r\n\r\n\r\nlendingrf_last_fit%>% \r\n  collect_metrics()\r\n\r\n\r\n# A tibble: 2 x 4\r\n  .metric  .estimator .estimate .config             \r\n  <chr>    <chr>          <dbl> <chr>               \r\n1 accuracy binary         0.995 Preprocessor1_Model1\r\n2 roc_auc  binary         1.00  Preprocessor1_Model1\r\n\r\nThen we use the DALEX and DALEXtra libraries to build plots of the residuals of each of the models.\r\n\r\n\r\nlasso_explain <-\r\n  explain_tidymodels(\r\n    model = lending_lasso_final_mod,\r\n    data = lending_training %>% select(-Class),\r\n    y = as.numeric(lending_training %>%  pull(Class)),\r\n    label = \"lasso\"\r\n  )\r\n\r\n\r\nPreparation of a new explainer is initiated\r\n  -> model label       :  lasso \r\n  -> data              :  9643  rows  20  cols \r\n  -> data              :  tibble converted into a data.frame \r\n  -> target variable   :  9643  values \r\n  -> predict function  :  yhat.workflow  will be used ( [33m default [39m )\r\n  -> predicted values  :  No value for predict function target column. ( [33m default [39m )\r\n  -> model_info        :  package tidymodels , ver. 0.1.2 , task classification ( [33m default [39m ) \r\n  -> predicted values  :  numerical, min =  0.01086639 , mean =  0.7258119 , max =  0.9996281  \r\n  -> residual function :  difference between y and yhat ( [33m default [39m )\r\n  -> residuals         :  numerical, min =  0.01858075 , mean =  0.9999996 , max =  1.989134  \r\n [32m A new explainer has been created! [39m \r\n\r\nrf_explain <- \r\n  explain_tidymodels(\r\n    model = lendingrf_final_mod,\r\n    data = lending_training %>% select(-Class), \r\n    y = as.numeric(lending_training %>%  pull(Class)),\r\n    label = \"rf\"\r\n  )\r\n\r\n\r\nPreparation of a new explainer is initiated\r\n  -> model label       :  rf \r\n  -> data              :  9643  rows  20  cols \r\n  -> data              :  tibble converted into a data.frame \r\n  -> target variable   :  9643  values \r\n  -> predict function  :  yhat.workflow  will be used ( [33m default [39m )\r\n  -> predicted values  :  No value for predict function target column. ( [33m default [39m )\r\n  -> model_info        :  package tidymodels , ver. 0.1.2 , task classification ( [33m default [39m ) \r\n  -> predicted values  :  numerical, min =  0 , mean =  0.702576 , max =  1  \r\n  -> residual function :  difference between y and yhat ( [33m default [39m )\r\n  -> residuals         :  numerical, min =  0.55 , mean =  1.023236 , max =  1.35  \r\n [32m A new explainer has been created! [39m \r\n\r\n\r\n\r\nlasso_mod_perf <- model_performance(lasso_explain)\r\nrf_mod_perf <-  model_performance(rf_explain)\r\n\r\n\r\n\r\n\r\n\r\nhist_plot <- \r\n  plot(lasso_mod_perf,\r\n       rf_mod_perf, \r\n       geom = \"histogram\")\r\nbox_plot <-\r\n  plot(lasso_mod_perf,\r\n       rf_mod_perf, \r\n       geom = \"boxplot\")\r\n\r\nhist_plot + box_plot\r\n\r\n\r\n\r\n\r\nCreating a variable importance plot to check out the most significant predictors.\r\n\r\n\r\nset.seed(494) #since we are sampling & permuting, we set a seed so we can replicate the results\r\nlasso_var_imp <- \r\n  model_parts(\r\n    lasso_explain\r\n    )\r\n\r\nplot(lasso_var_imp, show_boxplots = TRUE)\r\n\r\n\r\n\r\nset.seed(10) #since we are sampling & permuting, we set a seed so we can replicate the results\r\nrf_var_imp <- \r\n  model_parts(\r\n    rf_explain\r\n    )\r\n\r\nplot(rf_var_imp, show_boxplots = TRUE)\r\n\r\n\r\n\r\n\r\nInterest rate, annual income and verification status seem to be very important predictors which is not all that suprising.\r\nNow we set up the knn model and tune k.\r\n\r\n\r\n# create a model definition\r\nknn_mod <-\r\n  nearest_neighbor(\r\n    neighbors = tune(\"k\")\r\n  ) %>%\r\n  set_engine(\"kknn\") %>% \r\n  set_mode(\"classification\")\r\n\r\n# create the workflow\r\nknn_wf <- \r\n  workflow() %>% \r\n  add_model(knn_mod) %>%\r\n  add_recipe(lending_recipe)\r\n\r\n# tune it using 4 tuning parameters\r\nknn_tune <- \r\n  knn_wf %>% \r\n  tune_grid(\r\n    lending_cv,\r\n    grid = 4,\r\n    control = control_stack_grid()\r\n  )\r\n\r\n\r\n\r\nCreate a model stack with the candidate models from the previous parts of the exercise and use the blend_predictions() function to find the coefficients of the stacked model. Create a plot examining the performance metrics for the different penalty parameters to assure you have captured the best one. If not, adjust the penalty. (HINT: use the autoplot() function). Which models are contributing most?\r\nNow we stack the 3 model tuning parameters and ‘blend’ them to optimize our final model.\r\n\r\n\r\nlending_stack <- \r\n  stacks() %>% \r\n   add_candidates(lendingrf_tune) %>% \r\n   add_candidates(lending_lasso_tune) %>% \r\n   add_candidates(knn_tune)\r\n\r\nas_tibble(lending_stack)\r\n\r\n\r\n# A tibble: 9,643 x 39\r\n   Class .pred_bad_lendingrf~ .pred_bad_lendingrf~ .pred_bad_lendingr~\r\n   <fct>                <dbl>                <dbl>               <dbl>\r\n 1 good                0.134                0.112               0.152 \r\n 2 good                0.195                0.213               0.183 \r\n 3 good                0.254                0.326               0.347 \r\n 4 good                0.119                0.127               0.196 \r\n 5 good                0.141                0.153               0.117 \r\n 6 good                0.129                0.110               0.130 \r\n 7 good                0.0589               0.0688              0.0468\r\n 8 good                0.102                0.0941              0.140 \r\n 9 good                0.0918               0.112               0.164 \r\n10 good                0.0593               0.0860              0.0674\r\n# ... with 9,633 more rows, and 35 more variables:\r\n#   .pred_bad_lendingrf_tune_1_2 <dbl>,\r\n#   .pred_bad_lendingrf_tune_1_5 <dbl>,\r\n#   .pred_bad_lendingrf_tune_1_8 <dbl>,\r\n#   .pred_bad_lendingrf_tune_1_3 <dbl>,\r\n#   .pred_bad_lendingrf_tune_1_6 <dbl>,\r\n#   .pred_bad_lendingrf_tune_1_9 <dbl>,\r\n#   .pred_good_lendingrf_tune_1_1 <dbl>,\r\n#   .pred_good_lendingrf_tune_1_4 <dbl>,\r\n#   .pred_good_lendingrf_tune_1_7 <dbl>,\r\n#   .pred_good_lendingrf_tune_1_2 <dbl>,\r\n#   .pred_good_lendingrf_tune_1_5 <dbl>,\r\n#   .pred_good_lendingrf_tune_1_8 <dbl>,\r\n#   .pred_good_lendingrf_tune_1_3 <dbl>,\r\n#   .pred_good_lendingrf_tune_1_6 <dbl>,\r\n#   .pred_good_lendingrf_tune_1_9 <dbl>,\r\n#   .pred_bad_lending_lasso_tune_1_01 <dbl>,\r\n#   .pred_bad_lending_lasso_tune_1_06 <dbl>,\r\n#   .pred_bad_lending_lasso_tune_1_07 <dbl>,\r\n#   .pred_bad_lending_lasso_tune_1_08 <dbl>,\r\n#   .pred_bad_lending_lasso_tune_1_09 <dbl>,\r\n#   .pred_bad_lending_lasso_tune_1_10 <dbl>,\r\n#   .pred_good_lending_lasso_tune_1_01 <dbl>,\r\n#   .pred_good_lending_lasso_tune_1_06 <dbl>,\r\n#   .pred_good_lending_lasso_tune_1_07 <dbl>,\r\n#   .pred_good_lending_lasso_tune_1_08 <dbl>,\r\n#   .pred_good_lending_lasso_tune_1_09 <dbl>,\r\n#   .pred_good_lending_lasso_tune_1_10 <dbl>,\r\n#   .pred_bad_knn_tune_1_1 <dbl>, .pred_bad_knn_tune_1_2 <dbl>,\r\n#   .pred_bad_knn_tune_1_3 <dbl>, .pred_bad_knn_tune_1_4 <dbl>,\r\n#   .pred_good_knn_tune_1_1 <dbl>, .pred_good_knn_tune_1_2 <dbl>,\r\n#   .pred_good_knn_tune_1_3 <dbl>, .pred_good_knn_tune_1_4 <dbl>\r\n\r\n\r\n\r\nlending_blend <- \r\n  lending_stack %>% \r\n  blend_predictions() \r\n\r\n\r\n\r\n\r\n\r\nautoplot(lending_blend)\r\n\r\n\r\n\r\n\r\n\r\n\r\nlending_blend\r\n\r\n\r\n# A tibble: 3 x 3\r\n  member                        type             weight\r\n  <chr>                         <chr>             <dbl>\r\n1 .pred_good_lendingrf_tune_1_2 rand_forest      4.57  \r\n2 .pred_good_lendingrf_tune_1_3 rand_forest      0.321 \r\n3 .pred_good_knn_tune_1_1       nearest_neighbor 0.0188\r\n\r\nWe then create the model stack and apply it onto our test data to see how it performs.\r\n\r\n\r\nlending_final_stack <- lending_blend %>% \r\n  fit_members()\r\n\r\n\r\n\r\n\r\n\r\n  lending_final_stack %>% \r\n  predict(new_data = lending_testing) %>% \r\n  bind_cols(lending_testing)\r\n\r\n\r\n# A tibble: 3,214 x 22\r\n   .pred_class funded_amnt term    int_rate sub_grade addr_state\r\n   <fct>             <int> <fct>      <dbl> <fct>     <fct>     \r\n 1 good              25750 term_36    13.7  C3        MI        \r\n 2 good              15000 term_60    15.8  D1        TX        \r\n 3 good              20000 term_36    10.8  B4        TN        \r\n 4 good              19350 term_36    11.5  B5        MI        \r\n 5 good              15000 term_36    10.8  B4        TX        \r\n 6 good              20400 term_60    14.5  C4        GA        \r\n 7 good              22000 term_60    13.7  C3        MN        \r\n 8 good              27200 term_60    10.8  B4        NC        \r\n 9 good              10000 term_36     6.49 A2        NY        \r\n10 good              30000 term_60    20.8  E2        IL        \r\n# ... with 3,204 more rows, and 16 more variables:\r\n#   verification_status <fct>, annual_inc <dbl>, emp_length <fct>,\r\n#   delinq_2yrs <int>, inq_last_6mths <int>, revol_util <dbl>,\r\n#   open_il_6m <int>, open_il_12m <int>, open_il_24m <int>,\r\n#   total_bal_il <int>, all_util <int>, inq_fi <int>,\r\n#   inq_last_12m <int>, num_il_tl <int>,\r\n#   total_il_high_credit_limit <int>, Class <fct>\r\n\r\n\r\n\r\npred_compare <- lending_final_stack %>% \r\n  predict(new_data = lending_testing) %>% \r\n  bind_cols(lending_testing) %>% \r\n  select(.pred_class,Class) \r\n\r\n\r\n\r\n\r\n\r\npredictions <- pred_compare %>% \r\n  pull(.pred_class)\r\ntrue_class <- pred_compare %>% \r\n  pull(Class)\r\n\r\n\r\n\r\n\r\n\r\nroc.curve(true_class, predictions)\r\n\r\n\r\n\r\nArea under the curve (AUC): 0.990\r\n\r\nWe get an auc_roc of 0.95 which is very very good for a classification model of this nature.\r\nShiny app\r\nWork In Progress.\r\n\r\n\r\n\r\n",
    "preview": "posts/2021-04-06-lendingclubarticle/lendingclubarticle_files/figure-html5/unnamed-chunk-2-1.png",
    "last_modified": "2021-04-06T16:04:28-05:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-04-06-tidytextarticle/",
    "title": "TidyText Tutorial",
    "description": "An introductory tutorial with excercises about the TidyText package",
    "author": [
      {
        "name": "Colleen Minnihan, Jackson Tak, Niketh Gamage",
        "url": {}
      }
    ],
    "date": "2021-04-06",
    "categories": [],
    "contents": "\r\n1. Tutorial\r\nIntroduction\r\nToday, we will talk about the TidyText package. The tidytext packages allows us to effectively do text mining tasks by converting text data into tidy formats. We can then incorporated these tidy data sets with other tools in data science or machine learning.\r\nIn this tutorial, we will explain some of the key functions used in the tidytext package by using a simple example. We will then ask you to work on questions using a different data set: Russian Troll Tweets.\r\n\r\nGetting Started\r\nLoading Libraries\r\nFirst, as always, we have to load libraries and install packages. You will encounter some familiar packages, but the main libraries required to do text mining with tidytext are listed below:\r\n\r\n\r\n\r\n\r\nLooking at the Data Set\r\nAfter loading all the relevant libraries, we will look at a simple data set that we created. The text data set includes 9 different sentences or strings.\r\n\r\n[1] \"Lisa is awesome\"         \"I love Data Science\"    \r\n[3] \"I hate cilantro\"         \"I dislike vegetables\"   \r\n[5] \"I enjoy smiling\"         \"I hate exams\"           \r\n[7] \"I love travelling\"       \"The weather is so nice!\"\r\n[9] \"Can I have an apple?\"   \r\n\r\nThe first task before doing text analysis is converting our data set into a tibble data frame by using the tibble function. A tibble is just another class of data frames in R, which allows us to work with tidy functions, as it does not convert strings to factors or use row names.\r\nTake a look at how we were able to achieve this below:\r\n\r\n# A tibble: 9 x 2\r\n   line text                   \r\n  <int> <chr>                  \r\n1     1 Lisa is awesome        \r\n2     2 I love Data Science    \r\n3     3 I hate cilantro        \r\n4     4 I dislike vegetables   \r\n5     5 I enjoy smiling        \r\n6     6 I hate exams           \r\n7     7 I love travelling      \r\n8     8 The weather is so nice!\r\n9     9 Can I have an apple?   \r\n\r\nAfter we successfully convert our data set into a tibble data frame, we want to extract individual words and put them into a data frame so that each row has one token.\r\nEach token can be interpreted as a word or unit of text. By utilizing tidytext’s unnest_tokens function, we can break the text into individual tokens. This process is also known as the tokenization process. Note that this function eliminates all the punctuation marks.\r\n\r\n# A tibble: 32 x 2\r\n    line word    \r\n   <int> <chr>   \r\n 1     1 lisa    \r\n 2     1 is      \r\n 3     1 awesome \r\n 4     2 i       \r\n 5     2 love    \r\n 6     2 data    \r\n 7     2 science \r\n 8     3 i       \r\n 9     3 hate    \r\n10     3 cilantro\r\n# ... with 22 more rows\r\n\r\nAs we see above, the unnest_tokens function takes in two parameters. The first parameter, the output column, will be the name of the output column or individual words. In our exercise, we will call it word.\r\nThe second parameter will take the tokenized column name from the tibble data frame.\r\nBefore starting our text analysis, we will also have to exclude stop words such as “is”, “I”, “the”, “about”, “an”, “the”, etc. The tidytext package provides a tibble data set called stop_words that includes different stop words.\r\nYou can take a peek at some of the stop words in the stop_words data set:\r\n\r\n# A tibble: 6 x 2\r\n  word      lexicon\r\n  <chr>     <chr>  \r\n1 a         SMART  \r\n2 a's       SMART  \r\n3 able      SMART  \r\n4 about     SMART  \r\n5 above     SMART  \r\n6 according SMART  \r\n\r\nFinally, we will use a familiar function, anti_join, to clean the data set. This is the last step of the data cleaning process that we need to do before moving forward with the analysis. By joining the two data sets, stop_words and text_unnest, we can arrive at a clean data set.\r\n\r\n# A tibble: 18 x 2\r\n    line word      \r\n   <int> <chr>     \r\n 1     1 lisa      \r\n 2     1 awesome   \r\n 3     2 love      \r\n 4     2 data      \r\n 5     2 science   \r\n 6     3 hate      \r\n 7     3 cilantro  \r\n 8     4 dislike   \r\n 9     4 vegetables\r\n10     5 enjoy     \r\n11     5 smiling   \r\n12     6 hate      \r\n13     6 exams     \r\n14     7 love      \r\n15     7 travelling\r\n16     8 weather   \r\n17     8 nice      \r\n18     9 apple     \r\n\r\n\r\nData Analysis\r\nWith the cleaned version of the data, we will begin our analysis. In this tutorial, we mainly focus on the sentiment analysis and creating relevant visualizations using word cloud\r\n\r\nSentiment Analysis\r\nBefore beginning the sentiment analysis, let’s take a step back and understand the purpose of sentiment analysis. Sentiment analysis “provides a way to understand the attitudes and opinions expressed in texts”.\r\nTo conduct sentiment analysis, we will be first looking at the get_sentiments(). By using this function within the tidytext package, we can look at words with negative and positive sentiments. Note that this function takes in a lexicon parameter. There are three sentiment lexicons that we can use:\r\nbing (default): positive vs. negative\r\nnrc: assigns yes vs. no to positive, negative, anger, anticipation, disgust, fear, joy, sadness, surprise, and trust cateogries.\r\nAFINN: assigns scores from -5 to 5 depending on the sentiment of the word.\r\nFor this tutorial, we will use bing for simplicity. Feel free to play with other lexicons.\r\n\r\n# A tibble: 6 x 2\r\n  word       sentiment\r\n  <chr>      <chr>    \r\n1 2-faces    negative \r\n2 abnormal   negative \r\n3 abolish    negative \r\n4 abominable negative \r\n5 abominably negative \r\n6 abominate  negative \r\n# A tibble: 6 x 2\r\n  word       sentiment\r\n  <chr>      <chr>    \r\n1 abound     positive \r\n2 abounds    positive \r\n3 abundance  positive \r\n4 abundant   positive \r\n5 accessable positive \r\n6 accessible positive \r\n\r\nNext, to figure out the sentiment for each word, we will join the two data sets: sentiments and text_clean. Note that some words in the text_clean data set are dropped i.e., “exams”, “weather”, “apple”, etc.\r\n\r\n# A tibble: 9 x 3\r\n   line word    sentiment\r\n  <int> <chr>   <chr>    \r\n1     1 awesome positive \r\n2     2 love    positive \r\n3     3 hate    negative \r\n4     4 dislike negative \r\n5     5 enjoy   positive \r\n6     5 smiling positive \r\n7     6 hate    negative \r\n8     7 love    positive \r\n9     8 nice    positive \r\n\r\nUsing this sentiment data, we will now begin the sentiment analysis by using some functions that we already know.\r\n\r\n# A tibble: 2 x 2\r\n  sentiment     n\r\n* <chr>     <int>\r\n1 negative      3\r\n2 positive      6\r\n\r\nFrom above, We see that there are 3 negative words and 6 positive words.\r\n\r\nMaking cool visualizations using WordCloud\r\nWith the above analysis in mind, we can also create interesting visualizations using the wordcloud package.\r\nUsing the text_clean data (without sentiments), we can create this nice visualization which shows us all the words in the data set. Note that the size of “hate” and “love” are bigger than other words. This is because they appear more than other words.\r\n\r\n\r\n\r\nUsing the data set that includes sentiments, we can also create a similar visualization.\r\n\r\n\r\n\r\nCompared to the first wordcloud visualization, this one allows us to make a comparison. Through this visualization, we can understand what words have positive and negative associations and what words appear more than the others within their specific groups.\r\n\r\nOther notable functions in the tidytext package\r\nFor the purpose of this tutorial, we selected some of the tidytext functions. However, there are many more functions that you might be interested in using for your final project if your group were to do some text mining and analysis.\r\nOther functions and their documentations can be found in the link below:\r\nhttps://cran.r-project.org/web/packages/tidytext/tidytext.pdf\r\n\r\n2. Exercises\r\nNow you will try using tidytext on a new dataset about Russian Troll tweets.\r\n\r\nRead about the data\r\nThese are tweets from Twitter handles that are connected to the Internet Research Agency (IRA), a Russian “troll factory.” The majority of these tweets were posted from 2015-2017, but the datasets encompass tweets from February 2012 to May 2018.\r\nThree of the main categories of troll tweet that we will be focusing on are Left Trolls, Right Trolls, and News Feed. Left Trolls usually pretend to be BLM activists, aiming to divide the democratic party (in this context, being pro-Bernie so that votes are taken away from Hillary). Right trolls imitate Trump supporters, and News Feed handles are “local news aggregators,” typically linking to legitimate news.\r\nFor our upcoming analyses, some important variables are:\r\nauthor (handle sending the tweet)\r\ncontent (text of the tweet)\r\nlanguage (language of the tweet)\r\npublish_date (date and time the tweet was sent)\r\nVariable documentation can be found on Github and a more detailed description of the dataset can be found in this fivethirtyeight article.\r\nBecause there are 12 datasets containing 2,973,371 tweets sent by 2,848 Twitter handles in total, we will be using three of these datasets (one from a Right troll, one from a Left troll, and one from a News Feed account).\r\n\r\n1. Read in Troll Tweets Dataset\r\n\r\n\r\n\r\n\r\n2. Basic Data Cleaning and Exploration\r\nRemove rows where the tweet was in a language other than English\r\nReport the dimensions of the dataset\r\nCreate two or three basic exploratory plots of the data (ex. plot of the different locations from which tweets were posted, plot of the account category of a tweet)\r\n\r\n\r\n\r\n\r\n3. Unnest Tokens\r\nWe want each row to represent a word from a tweet, rather than an entire tweet.\r\n\r\n\r\n\r\n\r\n4. Remove stopwords\r\n\r\n\r\n\r\nTake a look at the troll_tweets_cleaned dataset. Are there any other words/letters/numbers that we want to eliminate that weren’t taken care of by stop_words?\r\n\r\n\r\n\r\n\r\n5. Look at a subset of the tweets to see how often the top words appear.\r\n\r\n\r\n\r\n\r\n6. Sentiment Analysis\r\nGet the sentiments using the “bing” parameter (which classifies words into “positive” or “negative”)\r\nReport how many positive and negative words there are in the dataset. Are there more positive or negative words, and why do you think this might be?\r\n\r\n\r\n\r\n\r\n\r\n\r\n7. Using the troll_tweets_small dataset, make a wordcloud:\r\nThat is sized by the number of times that a word appears in the tweets\r\nThat is colored by sentiment (positive or negative)\r\n\r\n\r\n\r\nAre there any words whose categorization as “positive” or “negative” surprised you?\r\n\r\nSources\r\nhttps://cran.r-project.org/web/packages/tidytext/tidytext.pdf\r\nhttps://www.tidytextmining.com/\r\nhttps://fivethirtyeight.com/features/why-were-sharing-3-million-russian-troll-tweets\r\nhttps://www.youtube.com/watch?v=-uVo0Xvmimw\r\nhttps://github.com/fivethirtyeight/russian-troll-tweets/\r\n\r\n\r\n\r\n",
    "preview": "posts/2021-04-06-tidytextarticle/tidytextarticle_files/figure-html5/unnamed-chunk-10-1.png",
    "last_modified": "2021-04-06T15:55:07-05:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-04-04-nuclearexplosions/",
    "title": "Nuclear Explosions",
    "description": "This a small story about nuclear detonations told with some exploratory data visualization and analysis.",
    "author": [
      {
        "name": "Niketh Gamage",
        "url": {}
      }
    ],
    "date": "2021-04-04",
    "categories": [],
    "contents": "\r\nOverview\r\nNuclear weapons are the deadliest weapons known to man. In this dataset(which can be found here), we will be exploring the history of nuclear weapons detonation in the world. The data used for this analysis spans from 1945 - 1998, so the results of the analysis presented here are as of 1998.\r\nI will go about answering these questions:\r\nWhat are the countries with nuclear weapons capability and when did they achieve this?\r\nWhich country has detonated the most nuclear weapons?\r\nHow have these detonation patterns varied over time - what effect did the fall of the Soviet Union have on this?\r\nWhere were these nuclear weapons detonated?\r\nWhich countries definitevely have a fusion bomb(2nd generation of nukes)?\r\nHow did methods of testing them change over time?\r\nSimple application that lets you compare the countries nuclear detonation activity over time.\r\n1. When did each country first test a nuclear weapon?\r\n\r\n\r\n{\"x\":{\"data\":[{\"x\":[1942.35,2000.65],\"y\":[0,0],\"text\":\"yintercept: 0\",\"type\":\"scatter\",\"mode\":\"lines\",\"line\":{\"width\":1.13385826771654,\"color\":\"rgba(0,0,0,1)\",\"dash\":\"solid\"},\"hoveron\":\"points\",\"showlegend\":false,\"xaxis\":\"x\",\"yaxis\":\"y\",\"hoverinfo\":\"text\",\"frame\":null},{\"x\":[1964],\"y\":[0],\"text\":\"first_bomb: 1964<br />y: 0<br />country: CHINA\",\"type\":\"scatter\",\"mode\":\"markers\",\"marker\":{\"autocolorscale\":false,\"color\":\"rgba(248,118,109,1)\",\"opacity\":1,\"size\":5.66929133858268,\"symbol\":\"circle\",\"line\":{\"width\":1.88976377952756,\"color\":\"rgba(248,118,109,1)\"}},\"hoveron\":\"points\",\"name\":\"CHINA\",\"legendgroup\":\"CHINA\",\"showlegend\":true,\"xaxis\":\"x\",\"yaxis\":\"y\",\"hoverinfo\":\"text\",\"frame\":null},{\"x\":[1960],\"y\":[0],\"text\":\"first_bomb: 1960<br />y: 0<br />country: FRANCE\",\"type\":\"scatter\",\"mode\":\"markers\",\"marker\":{\"autocolorscale\":false,\"color\":\"rgba(196,154,0,1)\",\"opacity\":1,\"size\":5.66929133858268,\"symbol\":\"circle\",\"line\":{\"width\":1.88976377952756,\"color\":\"rgba(196,154,0,1)\"}},\"hoveron\":\"points\",\"name\":\"FRANCE\",\"legendgroup\":\"FRANCE\",\"showlegend\":true,\"xaxis\":\"x\",\"yaxis\":\"y\",\"hoverinfo\":\"text\",\"frame\":null},{\"x\":[1974],\"y\":[0],\"text\":\"first_bomb: 1974<br />y: 0<br />country: INDIA\",\"type\":\"scatter\",\"mode\":\"markers\",\"marker\":{\"autocolorscale\":false,\"color\":\"rgba(83,180,0,1)\",\"opacity\":1,\"size\":5.66929133858268,\"symbol\":\"circle\",\"line\":{\"width\":1.88976377952756,\"color\":\"rgba(83,180,0,1)\"}},\"hoveron\":\"points\",\"name\":\"INDIA\",\"legendgroup\":\"INDIA\",\"showlegend\":true,\"xaxis\":\"x\",\"yaxis\":\"y\",\"hoverinfo\":\"text\",\"frame\":null},{\"x\":[1998],\"y\":[0],\"text\":\"first_bomb: 1998<br />y: 0<br />country: PAKIST\",\"type\":\"scatter\",\"mode\":\"markers\",\"marker\":{\"autocolorscale\":false,\"color\":\"rgba(0,192,148,1)\",\"opacity\":1,\"size\":5.66929133858268,\"symbol\":\"circle\",\"line\":{\"width\":1.88976377952756,\"color\":\"rgba(0,192,148,1)\"}},\"hoveron\":\"points\",\"name\":\"PAKIST\",\"legendgroup\":\"PAKIST\",\"showlegend\":true,\"xaxis\":\"x\",\"yaxis\":\"y\",\"hoverinfo\":\"text\",\"frame\":null},{\"x\":[1952],\"y\":[0],\"text\":\"first_bomb: 1952<br />y: 0<br />country: UK\",\"type\":\"scatter\",\"mode\":\"markers\",\"marker\":{\"autocolorscale\":false,\"color\":\"rgba(0,182,235,1)\",\"opacity\":1,\"size\":5.66929133858268,\"symbol\":\"circle\",\"line\":{\"width\":1.88976377952756,\"color\":\"rgba(0,182,235,1)\"}},\"hoveron\":\"points\",\"name\":\"UK\",\"legendgroup\":\"UK\",\"showlegend\":true,\"xaxis\":\"x\",\"yaxis\":\"y\",\"hoverinfo\":\"text\",\"frame\":null},{\"x\":[1945],\"y\":[0],\"text\":\"first_bomb: 1945<br />y: 0<br />country: USA\",\"type\":\"scatter\",\"mode\":\"markers\",\"marker\":{\"autocolorscale\":false,\"color\":\"rgba(165,138,255,1)\",\"opacity\":1,\"size\":5.66929133858268,\"symbol\":\"circle\",\"line\":{\"width\":1.88976377952756,\"color\":\"rgba(165,138,255,1)\"}},\"hoveron\":\"points\",\"name\":\"USA\",\"legendgroup\":\"USA\",\"showlegend\":true,\"xaxis\":\"x\",\"yaxis\":\"y\",\"hoverinfo\":\"text\",\"frame\":null},{\"x\":[1949],\"y\":[0],\"text\":\"first_bomb: 1949<br />y: 0<br />country: USSR\",\"type\":\"scatter\",\"mode\":\"markers\",\"marker\":{\"autocolorscale\":false,\"color\":\"rgba(251,97,215,1)\",\"opacity\":1,\"size\":5.66929133858268,\"symbol\":\"circle\",\"line\":{\"width\":1.88976377952756,\"color\":\"rgba(251,97,215,1)\"}},\"hoveron\":\"points\",\"name\":\"USSR\",\"legendgroup\":\"USSR\",\"showlegend\":true,\"xaxis\":\"x\",\"yaxis\":\"y\",\"hoverinfo\":\"text\",\"frame\":null}],\"layout\":{\"margin\":{\"t\":45.4063926940639,\"r\":7.30593607305936,\"b\":27.2146118721461,\"l\":10.958904109589},\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":14.6118721461187},\"title\":{\"text\":\"First Nuclear Detonation by Country\",\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":17.5342465753425},\"x\":0,\"xref\":\"paper\"},\"xaxis\":{\"domain\":[0,1],\"automargin\":true,\"type\":\"linear\",\"autorange\":false,\"range\":[1942.35,2000.65],\"tickmode\":\"array\",\"ticktext\":[\"1950\",\"1960\",\"1970\",\"1980\",\"1990\",\"2000\"],\"tickvals\":[1950,1960,1970,1980,1990,2000],\"categoryorder\":\"array\",\"categoryarray\":[\"1950\",\"1960\",\"1970\",\"1980\",\"1990\",\"2000\"],\"nticks\":null,\"ticks\":\"\",\"tickcolor\":null,\"ticklen\":3.65296803652968,\"tickwidth\":0,\"showticklabels\":true,\"tickfont\":{\"color\":\"rgba(77,77,77,1)\",\"family\":\"\",\"size\":11.689497716895},\"tickangle\":-0,\"showline\":false,\"linecolor\":null,\"linewidth\":0,\"showgrid\":false,\"gridcolor\":null,\"gridwidth\":0,\"zeroline\":false,\"anchor\":\"y\",\"title\":{\"text\":\"\",\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":14.6118721461187}},\"hoverformat\":\".2f\"},\"yaxis\":{\"domain\":[0,1],\"automargin\":true,\"type\":\"linear\",\"autorange\":false,\"range\":[-0.05,0.05],\"tickmode\":\"array\",\"ticktext\":[\"-0.050\",\"-0.025\",\"0.000\",\"0.025\",\"0.050\"],\"tickvals\":[-0.05,-0.025,0,0.025,0.05],\"categoryorder\":\"array\",\"categoryarray\":[\"-0.050\",\"-0.025\",\"0.000\",\"0.025\",\"0.050\"],\"nticks\":null,\"ticks\":\"\",\"tickcolor\":null,\"ticklen\":3.65296803652968,\"tickwidth\":0,\"showticklabels\":false,\"tickfont\":{\"color\":null,\"family\":null,\"size\":0},\"tickangle\":-0,\"showline\":false,\"linecolor\":null,\"linewidth\":0,\"showgrid\":false,\"gridcolor\":null,\"gridwidth\":0,\"zeroline\":false,\"anchor\":\"x\",\"title\":{\"text\":\"\",\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":14.6118721461187}},\"hoverformat\":\".2f\"},\"shapes\":[{\"type\":\"rect\",\"fillcolor\":null,\"line\":{\"color\":null,\"width\":0,\"linetype\":[]},\"yref\":\"paper\",\"xref\":\"paper\",\"x0\":0,\"x1\":1,\"y0\":0,\"y1\":1}],\"showlegend\":true,\"legend\":{\"bgcolor\":null,\"bordercolor\":null,\"borderwidth\":0,\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":11.689497716895},\"y\":0.959399606299213},\"annotations\":[{\"text\":\"country\",\"x\":1.02,\"y\":1,\"showarrow\":false,\"ax\":0,\"ay\":0,\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":14.6118721461187},\"xref\":\"paper\",\"yref\":\"paper\",\"textangle\":-0,\"xanchor\":\"left\",\"yanchor\":\"bottom\",\"legendTitle\":true}],\"hovermode\":\"closest\",\"barmode\":\"relative\"},\"config\":{\"doubleClick\":\"reset\",\"showSendToCloud\":false},\"source\":\"A\",\"attrs\":{\"141842d3a9a\":{\"yintercept\":{},\"type\":\"scatter\"},\"141842046b43\":{\"x\":{},\"y\":{},\"colour\":{}}},\"cur_data\":\"141842d3a9a\",\"visdat\":{\"141842d3a9a\":[\"function (y) \",\"x\"],\"141842046b43\":[\"function (y) \",\"x\"]},\"highlight\":{\"on\":\"plotly_click\",\"persistent\":false,\"dynamic\":false,\"selectize\":false,\"opacityDim\":0.2,\"selected\":{\"opacity\":1},\"debounce\":0},\"shinyEvents\":[\"plotly_hover\",\"plotly_click\",\"plotly_selected\",\"plotly_relayout\",\"plotly_brushed\",\"plotly_brushing\",\"plotly_clickannotation\",\"plotly_doubleclick\",\"plotly_deselect\",\"plotly_afterplot\",\"plotly_sunburstclick\"],\"base_url\":\"https://plot.ly\"},\"evals\":[],\"jsHooks\":[]}\r\nHere we see a timeline which shows all the nuclear powers in the world(as of 1998) and when they first reached this capability. In order of first detonation, these countries are the USA, USSR, UK, France, China, India and Pakistan.\r\n2. Which country has detonated the most nuclear weapons?\r\n\r\n\r\n{\"x\":{\"data\":[{\"orientation\":\"v\",\"width\":45,\"base\":2.55,\"x\":[22.5],\"y\":[0.9],\"text\":\"n:   45<br />fct_reorder(country, n): CHINA<br />country: CHINA\",\"type\":\"bar\",\"marker\":{\"autocolorscale\":false,\"color\":\"rgba(248,118,109,1)\",\"line\":{\"width\":1.88976377952756,\"color\":\"transparent\"}},\"name\":\"CHINA\",\"legendgroup\":\"CHINA\",\"showlegend\":true,\"xaxis\":\"x\",\"yaxis\":\"y\",\"hoverinfo\":\"text\",\"frame\":null},{\"orientation\":\"v\",\"width\":210,\"base\":4.55,\"x\":[105],\"y\":[0.9],\"text\":\"n:  210<br />fct_reorder(country, n): FRANCE<br />country: FRANCE\",\"type\":\"bar\",\"marker\":{\"autocolorscale\":false,\"color\":\"rgba(196,154,0,1)\",\"line\":{\"width\":1.88976377952756,\"color\":\"transparent\"}},\"name\":\"FRANCE\",\"legendgroup\":\"FRANCE\",\"showlegend\":true,\"xaxis\":\"x\",\"yaxis\":\"y\",\"hoverinfo\":\"text\",\"frame\":null},{\"orientation\":\"v\",\"width\":3,\"base\":1.55,\"x\":[1.5],\"y\":[0.9],\"text\":\"n:    3<br />fct_reorder(country, n): INDIA<br />country: INDIA\",\"type\":\"bar\",\"marker\":{\"autocolorscale\":false,\"color\":\"rgba(83,180,0,1)\",\"line\":{\"width\":1.88976377952756,\"color\":\"transparent\"}},\"name\":\"INDIA\",\"legendgroup\":\"INDIA\",\"showlegend\":true,\"xaxis\":\"x\",\"yaxis\":\"y\",\"hoverinfo\":\"text\",\"frame\":null},{\"orientation\":\"v\",\"width\":2,\"base\":0.55,\"x\":[1],\"y\":[0.9],\"text\":\"n:    2<br />fct_reorder(country, n): PAKIST<br />country: PAKIST\",\"type\":\"bar\",\"marker\":{\"autocolorscale\":false,\"color\":\"rgba(0,192,148,1)\",\"line\":{\"width\":1.88976377952756,\"color\":\"transparent\"}},\"name\":\"PAKIST\",\"legendgroup\":\"PAKIST\",\"showlegend\":true,\"xaxis\":\"x\",\"yaxis\":\"y\",\"hoverinfo\":\"text\",\"frame\":null},{\"orientation\":\"v\",\"width\":45,\"base\":3.55,\"x\":[22.5],\"y\":[0.9],\"text\":\"n:   45<br />fct_reorder(country, n): UK<br />country: UK\",\"type\":\"bar\",\"marker\":{\"autocolorscale\":false,\"color\":\"rgba(0,182,235,1)\",\"line\":{\"width\":1.88976377952756,\"color\":\"transparent\"}},\"name\":\"UK\",\"legendgroup\":\"UK\",\"showlegend\":true,\"xaxis\":\"x\",\"yaxis\":\"y\",\"hoverinfo\":\"text\",\"frame\":null},{\"orientation\":\"v\",\"width\":1032,\"base\":6.55,\"x\":[516],\"y\":[0.9],\"text\":\"n: 1032<br />fct_reorder(country, n): USA<br />country: USA\",\"type\":\"bar\",\"marker\":{\"autocolorscale\":false,\"color\":\"rgba(165,138,255,1)\",\"line\":{\"width\":1.88976377952756,\"color\":\"transparent\"}},\"name\":\"USA\",\"legendgroup\":\"USA\",\"showlegend\":true,\"xaxis\":\"x\",\"yaxis\":\"y\",\"hoverinfo\":\"text\",\"frame\":null},{\"orientation\":\"v\",\"width\":714,\"base\":5.55,\"x\":[357],\"y\":[0.9],\"text\":\"n:  714<br />fct_reorder(country, n): USSR<br />country: USSR\",\"type\":\"bar\",\"marker\":{\"autocolorscale\":false,\"color\":\"rgba(251,97,215,1)\",\"line\":{\"width\":1.88976377952756,\"color\":\"transparent\"}},\"name\":\"USSR\",\"legendgroup\":\"USSR\",\"showlegend\":true,\"xaxis\":\"x\",\"yaxis\":\"y\",\"hoverinfo\":\"text\",\"frame\":null}],\"layout\":{\"margin\":{\"t\":45.4063926940639,\"r\":7.30593607305936,\"b\":27.2146118721461,\"l\":46.027397260274},\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":14.6118721461187},\"title\":{\"text\":\"Total nuclear bomb detonations\",\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":17.5342465753425},\"x\":0,\"xref\":\"paper\"},\"xaxis\":{\"domain\":[0,1],\"automargin\":true,\"type\":\"linear\",\"autorange\":false,\"range\":[-51.6,1083.6],\"tickmode\":\"array\",\"ticktext\":[\"0\",\"250\",\"500\",\"750\",\"1000\"],\"tickvals\":[0,250,500,750,1000],\"categoryorder\":\"array\",\"categoryarray\":[\"0\",\"250\",\"500\",\"750\",\"1000\"],\"nticks\":null,\"ticks\":\"\",\"tickcolor\":null,\"ticklen\":3.65296803652968,\"tickwidth\":0,\"showticklabels\":true,\"tickfont\":{\"color\":\"rgba(77,77,77,1)\",\"family\":\"\",\"size\":11.689497716895},\"tickangle\":-0,\"showline\":false,\"linecolor\":null,\"linewidth\":0,\"showgrid\":true,\"gridcolor\":\"rgba(235,235,235,1)\",\"gridwidth\":0.66417600664176,\"zeroline\":false,\"anchor\":\"y\",\"title\":{\"text\":\"\",\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":14.6118721461187}},\"hoverformat\":\".2f\"},\"yaxis\":{\"domain\":[0,1],\"automargin\":true,\"type\":\"linear\",\"autorange\":false,\"range\":[0.4,7.6],\"tickmode\":\"array\",\"ticktext\":[\"PAKIST\",\"INDIA\",\"CHINA\",\"UK\",\"FRANCE\",\"USSR\",\"USA\"],\"tickvals\":[1,2,3,4,5,6,7],\"categoryorder\":\"array\",\"categoryarray\":[\"PAKIST\",\"INDIA\",\"CHINA\",\"UK\",\"FRANCE\",\"USSR\",\"USA\"],\"nticks\":null,\"ticks\":\"\",\"tickcolor\":null,\"ticklen\":3.65296803652968,\"tickwidth\":0,\"showticklabels\":true,\"tickfont\":{\"color\":\"rgba(77,77,77,1)\",\"family\":\"\",\"size\":11.689497716895},\"tickangle\":-0,\"showline\":false,\"linecolor\":null,\"linewidth\":0,\"showgrid\":false,\"gridcolor\":null,\"gridwidth\":0,\"zeroline\":false,\"anchor\":\"x\",\"title\":{\"text\":\"\",\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":14.6118721461187}},\"hoverformat\":\".2f\"},\"shapes\":[{\"type\":\"rect\",\"fillcolor\":null,\"line\":{\"color\":null,\"width\":0,\"linetype\":[]},\"yref\":\"paper\",\"xref\":\"paper\",\"x0\":0,\"x1\":1,\"y0\":0,\"y1\":1}],\"showlegend\":false,\"legend\":{\"bgcolor\":null,\"bordercolor\":null,\"borderwidth\":0,\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":11.689497716895}},\"hovermode\":\"closest\",\"barmode\":\"relative\"},\"config\":{\"doubleClick\":\"reset\",\"showSendToCloud\":false},\"source\":\"A\",\"attrs\":{\"14181bde4d58\":{\"x\":{},\"y\":{},\"fill\":{},\"type\":\"bar\"}},\"cur_data\":\"14181bde4d58\",\"visdat\":{\"14181bde4d58\":[\"function (y) \",\"x\"]},\"highlight\":{\"on\":\"plotly_click\",\"persistent\":false,\"dynamic\":false,\"selectize\":false,\"opacityDim\":0.2,\"selected\":{\"opacity\":1},\"debounce\":0},\"shinyEvents\":[\"plotly_hover\",\"plotly_click\",\"plotly_selected\",\"plotly_relayout\",\"plotly_brushed\",\"plotly_brushing\",\"plotly_clickannotation\",\"plotly_doubleclick\",\"plotly_deselect\",\"plotly_afterplot\",\"plotly_sunburstclick\"],\"base_url\":\"https://plot.ly\"},\"evals\":[],\"jsHooks\":[]}\r\nThe United States and the USSR comprise a large majority of the total nuclear detonations made.\r\n3. How have these detonation patterns varied over time - what effect did the fall of the Soviet Union have on this?\r\n\r\n\r\n{\"x\":{\"data\":[{\"orientation\":\"v\",\"width\":[0.900000000000091,0.900000000000091,0.900000000000091,0.900000000000091,0.900000000000091,0.900000000000091,0.900000000000091,0.900000000000091,0.900000000000091,0.900000000000091,0.900000000000091,0.900000000000091,0.900000000000091,0.900000000000091,0.900000000000091,0.900000000000091,0.900000000000091,0.900000000000091,0.900000000000091,0.900000000000091,0.900000000000091,0.900000000000091,0.900000000000091,0.900000000000091,0.900000000000091,0.900000000000091,0.900000000000091,0.900000000000091,0.900000000000091,0.900000000000091,0.900000000000091,0.900000000000091,0.900000000000091,0.900000000000091,0.900000000000091,0.900000000000091,0.900000000000091,0.900000000000091,0.900000000000091,0.900000000000091,0.900000000000091,0.900000000000091,0.900000000000091,0.900000000000091,0.900000000000091,0.900000000000091,0.900000000000091,0.900000000000091,0.900000000000091,0.900000000000091],\"base\":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\"x\":[1945,1946,1948,1949,1951,1952,1953,1954,1955,1956,1957,1958,1960,1961,1962,1963,1964,1965,1966,1967,1968,1969,1970,1971,1972,1973,1974,1975,1976,1977,1978,1979,1980,1981,1982,1983,1984,1985,1986,1987,1988,1989,1990,1991,1992,1993,1994,1995,1996,1998],\"y\":[3,2,3,1,18,11,18,16,24,33,55,116,3,71,178,50,60,58,76,64,79,67,64,53,56,48,55,44,51,54,66,58,54,50,49,55,57,36,23,47,40,28,18,14,8,1,2,7,3,4],\"text\":[\"year: 1945<br />n:   3\",\"year: 1946<br />n:   2\",\"year: 1948<br />n:   3\",\"year: 1949<br />n:   1\",\"year: 1951<br />n:  18\",\"year: 1952<br />n:  11\",\"year: 1953<br />n:  18\",\"year: 1954<br />n:  16\",\"year: 1955<br />n:  24\",\"year: 1956<br />n:  33\",\"year: 1957<br />n:  55\",\"year: 1958<br />n: 116\",\"year: 1960<br />n:   3\",\"year: 1961<br />n:  71\",\"year: 1962<br />n: 178\",\"year: 1963<br />n:  50\",\"year: 1964<br />n:  60\",\"year: 1965<br />n:  58\",\"year: 1966<br />n:  76\",\"year: 1967<br />n:  64\",\"year: 1968<br />n:  79\",\"year: 1969<br />n:  67\",\"year: 1970<br />n:  64\",\"year: 1971<br />n:  53\",\"year: 1972<br />n:  56\",\"year: 1973<br />n:  48\",\"year: 1974<br />n:  55\",\"year: 1975<br />n:  44\",\"year: 1976<br />n:  51\",\"year: 1977<br />n:  54\",\"year: 1978<br />n:  66\",\"year: 1979<br />n:  58\",\"year: 1980<br />n:  54\",\"year: 1981<br />n:  50\",\"year: 1982<br />n:  49\",\"year: 1983<br />n:  55\",\"year: 1984<br />n:  57\",\"year: 1985<br />n:  36\",\"year: 1986<br />n:  23\",\"year: 1987<br />n:  47\",\"year: 1988<br />n:  40\",\"year: 1989<br />n:  28\",\"year: 1990<br />n:  18\",\"year: 1991<br />n:  14\",\"year: 1992<br />n:   8\",\"year: 1993<br />n:   1\",\"year: 1994<br />n:   2\",\"year: 1995<br />n:   7\",\"year: 1996<br />n:   3\",\"year: 1998<br />n:   4\"],\"type\":\"bar\",\"marker\":{\"autocolorscale\":false,\"color\":\"rgba(160,32,240,1)\",\"line\":{\"width\":1.88976377952756,\"color\":\"transparent\"}},\"showlegend\":false,\"xaxis\":\"x\",\"yaxis\":\"y\",\"hoverinfo\":\"text\",\"frame\":null}],\"layout\":{\"margin\":{\"t\":45.4063926940639,\"r\":7.30593607305936,\"b\":41.8264840182648,\"l\":43.1050228310502},\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":14.6118721461187},\"title\":{\"text\":\"Total number of nuclear explosions by year\",\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":17.5342465753425},\"x\":0,\"xref\":\"paper\"},\"xaxis\":{\"domain\":[0,1],\"automargin\":true,\"type\":\"linear\",\"autorange\":false,\"range\":[1941.855,2001.145],\"tickmode\":\"array\",\"ticktext\":[\"1945\",\"1950\",\"1960\",\"1970\",\"1980\",\"1990\"],\"tickvals\":[1945,1950,1960,1970,1980,1990],\"categoryorder\":\"array\",\"categoryarray\":[\"1945\",\"1950\",\"1960\",\"1970\",\"1980\",\"1990\"],\"nticks\":null,\"ticks\":\"\",\"tickcolor\":null,\"ticklen\":3.65296803652968,\"tickwidth\":0,\"showticklabels\":true,\"tickfont\":{\"color\":\"rgba(77,77,77,1)\",\"family\":\"\",\"size\":11.689497716895},\"tickangle\":-0,\"showline\":false,\"linecolor\":null,\"linewidth\":0,\"showgrid\":false,\"gridcolor\":null,\"gridwidth\":0,\"zeroline\":false,\"anchor\":\"y\",\"title\":{\"text\":\"year\",\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":14.6118721461187}},\"hoverformat\":\".2f\"},\"yaxis\":{\"domain\":[0,1],\"automargin\":true,\"type\":\"linear\",\"autorange\":false,\"range\":[-8.9,186.9],\"tickmode\":\"array\",\"ticktext\":[\"0\",\"50\",\"100\",\"150\"],\"tickvals\":[0,50,100,150],\"categoryorder\":\"array\",\"categoryarray\":[\"0\",\"50\",\"100\",\"150\"],\"nticks\":null,\"ticks\":\"\",\"tickcolor\":null,\"ticklen\":3.65296803652968,\"tickwidth\":0,\"showticklabels\":true,\"tickfont\":{\"color\":\"rgba(77,77,77,1)\",\"family\":\"\",\"size\":11.689497716895},\"tickangle\":-0,\"showline\":false,\"linecolor\":null,\"linewidth\":0,\"showgrid\":false,\"gridcolor\":null,\"gridwidth\":0,\"zeroline\":false,\"anchor\":\"x\",\"title\":{\"text\":\"n\",\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":14.6118721461187}},\"hoverformat\":\".2f\"},\"shapes\":[{\"type\":\"rect\",\"fillcolor\":null,\"line\":{\"color\":null,\"width\":0,\"linetype\":[]},\"yref\":\"paper\",\"xref\":\"paper\",\"x0\":0,\"x1\":1,\"y0\":0,\"y1\":1}],\"showlegend\":false,\"legend\":{\"bgcolor\":null,\"bordercolor\":null,\"borderwidth\":0,\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":11.689497716895}},\"hovermode\":\"closest\",\"barmode\":\"relative\"},\"config\":{\"doubleClick\":\"reset\",\"showSendToCloud\":false},\"source\":\"A\",\"attrs\":{\"141811bf57a2\":{\"x\":{},\"y\":{},\"type\":\"bar\"}},\"cur_data\":\"141811bf57a2\",\"visdat\":{\"141811bf57a2\":[\"function (y) \",\"x\"]},\"highlight\":{\"on\":\"plotly_click\",\"persistent\":false,\"dynamic\":false,\"selectize\":false,\"opacityDim\":0.2,\"selected\":{\"opacity\":1},\"debounce\":0},\"shinyEvents\":[\"plotly_hover\",\"plotly_click\",\"plotly_selected\",\"plotly_relayout\",\"plotly_brushed\",\"plotly_brushing\",\"plotly_clickannotation\",\"plotly_doubleclick\",\"plotly_deselect\",\"plotly_afterplot\",\"plotly_sunburstclick\"],\"base_url\":\"https://plot.ly\"},\"evals\":[],\"jsHooks\":[]}\r\nThis is a very interesting distribution. We can see how the first weapons were developed in the mid 1940’s after which the testing heavily accelerated in the 1950’s before coming to an abrupt stop in 1959 (apparently due to a nuclear testing moratorium between the US, USSR and the UK from November 1958 to August 1961). However testing increased back up and remained at a consistently high level during the 2 decades from 1960 - 1980 which also corresponded to the peak of the cold war.\r\n1962 in particular was a crazy year with a total of 178 detonations performed - a nuclear explosion every other day. It is also interesting that this was the year where the world saw the Cuban Missile Crisis in which the tensions between the USA and the USSR peaked and the world appeared to be at the edge of a nuclear calamity.\r\nIn the mid to late 1980’s, testing dropped down significantly and plummeted furthermore in the 1990’s until there were only a couple of tests each year. The Soviet Union dissolved between 1988-1991 and it is interesting to see how the nuclear testing in the world fell sharply during and after this period.\r\n4. Where were these tested by each country? And how did this look over time?\r\n\r\n\r\n\r\nThe US appears to have tested in the mainland(mostly in Nevada) and in the Pacific over water and over some Island and some tests in the South Athlantic. The only 2 bombs used in combat ever can be observed over Japan. USSR tested all over their mainland, concentrated in small areas in the south in what appears to be modern day Kazakhstan, Uzbekistan and other former Soviet terriories and in the Novaya Zemlaya islands in the north. UK never tested on mainland, instead tested in Australia, off the coast of Australia and interstingly in mainland America(Nevada). France never tested in their mainland, but instead in what appears to be Algeria and in the South Pacific. China, India and Pakistan appear to have tested in their respective mainlands exclusively.\r\nHere we have a small animation displaying these detonations occuring over time around the world.\r\n\r\n\r\n\r\n5. Which countries definitevely have a fusion bomb(2nd generation of nukes) and what are the yields of the most destructive bombs for each country?\r\nFusion bombs are the 2nd generation of nuclear bombs - they use a fission bomb to activate a fusion reaction which releases a vast amount of energy. The destructive capabilities of fusion bombs can be several order of magnitudes higher than a regular fission bomb. Anything above 500kT yield is definitely a thermonuclear bomb(fusion bomb as opposed to a fission bomb) so here I explored which countries definitively have this capability (as of 1998).\r\n\r\n\r\n\r\nWe can observe at least 100 large fusion bomb tests in total. These have primarily undertaken by the USA and USSR but China, UK and France have definitely shown capability too (as of 1998) .\r\nThen we explore the yield of the strongest bombs produced by each country\r\n\r\n\r\n{\"x\":{\"data\":[{\"x\":[5],\"y\":[8000],\"text\":\"fct_reorder(country, yield_upper): CHINA<br />yield_upper:  8000<br />country: CHINA\",\"type\":\"scatter\",\"mode\":\"markers\",\"marker\":{\"autocolorscale\":false,\"color\":\"rgba(248,118,109,1)\",\"opacity\":1,\"size\":5.66929133858268,\"symbol\":\"circle\",\"line\":{\"width\":1.88976377952756,\"color\":\"rgba(248,118,109,1)\"}},\"hoveron\":\"points\",\"name\":\"CHINA\",\"legendgroup\":\"CHINA\",\"showlegend\":true,\"xaxis\":\"x\",\"yaxis\":\"y\",\"hoverinfo\":\"text\",\"frame\":null},{\"x\":[3],\"y\":[1000],\"text\":\"fct_reorder(country, yield_upper): FRANCE<br />yield_upper:  1000<br />country: FRANCE\",\"type\":\"scatter\",\"mode\":\"markers\",\"marker\":{\"autocolorscale\":false,\"color\":\"rgba(196,154,0,1)\",\"opacity\":1,\"size\":5.66929133858268,\"symbol\":\"circle\",\"line\":{\"width\":1.88976377952756,\"color\":\"rgba(196,154,0,1)\"}},\"hoveron\":\"points\",\"name\":\"FRANCE\",\"legendgroup\":\"FRANCE\",\"showlegend\":true,\"xaxis\":\"x\",\"yaxis\":\"y\",\"hoverinfo\":\"text\",\"frame\":null},{\"x\":[1],\"y\":[20],\"text\":\"fct_reorder(country, yield_upper): INDIA<br />yield_upper:    20<br />country: INDIA\",\"type\":\"scatter\",\"mode\":\"markers\",\"marker\":{\"autocolorscale\":false,\"color\":\"rgba(83,180,0,1)\",\"opacity\":1,\"size\":5.66929133858268,\"symbol\":\"circle\",\"line\":{\"width\":1.88976377952756,\"color\":\"rgba(83,180,0,1)\"}},\"hoveron\":\"points\",\"name\":\"INDIA\",\"legendgroup\":\"INDIA\",\"showlegend\":true,\"xaxis\":\"x\",\"yaxis\":\"y\",\"hoverinfo\":\"text\",\"frame\":null},{\"x\":[2],\"y\":[35],\"text\":\"fct_reorder(country, yield_upper): PAKIST<br />yield_upper:    35<br />country: PAKIST\",\"type\":\"scatter\",\"mode\":\"markers\",\"marker\":{\"autocolorscale\":false,\"color\":\"rgba(0,192,148,1)\",\"opacity\":1,\"size\":5.66929133858268,\"symbol\":\"circle\",\"line\":{\"width\":1.88976377952756,\"color\":\"rgba(0,192,148,1)\"}},\"hoveron\":\"points\",\"name\":\"PAKIST\",\"legendgroup\":\"PAKIST\",\"showlegend\":true,\"xaxis\":\"x\",\"yaxis\":\"y\",\"hoverinfo\":\"text\",\"frame\":null},{\"x\":[4],\"y\":[3000],\"text\":\"fct_reorder(country, yield_upper): UK<br />yield_upper:  3000<br />country: UK\",\"type\":\"scatter\",\"mode\":\"markers\",\"marker\":{\"autocolorscale\":false,\"color\":\"rgba(0,182,235,1)\",\"opacity\":1,\"size\":5.66929133858268,\"symbol\":\"circle\",\"line\":{\"width\":1.88976377952756,\"color\":\"rgba(0,182,235,1)\"}},\"hoveron\":\"points\",\"name\":\"UK\",\"legendgroup\":\"UK\",\"showlegend\":true,\"xaxis\":\"x\",\"yaxis\":\"y\",\"hoverinfo\":\"text\",\"frame\":null},{\"x\":[6],\"y\":[15000],\"text\":\"fct_reorder(country, yield_upper): USA<br />yield_upper: 15000<br />country: USA\",\"type\":\"scatter\",\"mode\":\"markers\",\"marker\":{\"autocolorscale\":false,\"color\":\"rgba(165,138,255,1)\",\"opacity\":1,\"size\":5.66929133858268,\"symbol\":\"circle\",\"line\":{\"width\":1.88976377952756,\"color\":\"rgba(165,138,255,1)\"}},\"hoveron\":\"points\",\"name\":\"USA\",\"legendgroup\":\"USA\",\"showlegend\":true,\"xaxis\":\"x\",\"yaxis\":\"y\",\"hoverinfo\":\"text\",\"frame\":null},{\"x\":[7],\"y\":[50000],\"text\":\"fct_reorder(country, yield_upper): USSR<br />yield_upper: 50000<br />country: USSR\",\"type\":\"scatter\",\"mode\":\"markers\",\"marker\":{\"autocolorscale\":false,\"color\":\"rgba(251,97,215,1)\",\"opacity\":1,\"size\":5.66929133858268,\"symbol\":\"circle\",\"line\":{\"width\":1.88976377952756,\"color\":\"rgba(251,97,215,1)\"}},\"hoveron\":\"points\",\"name\":\"USSR\",\"legendgroup\":\"USSR\",\"showlegend\":true,\"xaxis\":\"x\",\"yaxis\":\"y\",\"hoverinfo\":\"text\",\"frame\":null}],\"layout\":{\"margin\":{\"t\":45.4063926940639,\"r\":7.30593607305936,\"b\":27.2146118721461,\"l\":54.7945205479452},\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":14.6118721461187},\"title\":{\"text\":\"Most Powerful Bombs by Country\",\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":17.5342465753425},\"x\":0,\"xref\":\"paper\"},\"xaxis\":{\"domain\":[0,1],\"automargin\":true,\"type\":\"linear\",\"autorange\":false,\"range\":[0.4,7.6],\"tickmode\":\"array\",\"ticktext\":[\"INDIA\",\"PAKIST\",\"FRANCE\",\"UK\",\"CHINA\",\"USA\",\"USSR\"],\"tickvals\":[1,2,3,4,5,6,7],\"categoryorder\":\"array\",\"categoryarray\":[\"INDIA\",\"PAKIST\",\"FRANCE\",\"UK\",\"CHINA\",\"USA\",\"USSR\"],\"nticks\":null,\"ticks\":\"\",\"tickcolor\":null,\"ticklen\":3.65296803652968,\"tickwidth\":0,\"showticklabels\":true,\"tickfont\":{\"color\":\"rgba(77,77,77,1)\",\"family\":\"\",\"size\":11.689497716895},\"tickangle\":-0,\"showline\":false,\"linecolor\":null,\"linewidth\":0,\"showgrid\":false,\"gridcolor\":null,\"gridwidth\":0,\"zeroline\":false,\"anchor\":\"y\",\"title\":{\"text\":\"\",\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":14.6118721461187}},\"hoverformat\":\".2f\"},\"yaxis\":{\"domain\":[0,1],\"automargin\":true,\"type\":\"linear\",\"autorange\":false,\"range\":[-2479,52499],\"tickmode\":\"array\",\"ticktext\":[\"0\",\"10000\",\"20000\",\"30000\",\"40000\",\"50000\"],\"tickvals\":[0,10000,20000,30000,40000,50000],\"categoryorder\":\"array\",\"categoryarray\":[\"0\",\"10000\",\"20000\",\"30000\",\"40000\",\"50000\"],\"nticks\":null,\"ticks\":\"\",\"tickcolor\":null,\"ticklen\":3.65296803652968,\"tickwidth\":0,\"showticklabels\":true,\"tickfont\":{\"color\":\"rgba(77,77,77,1)\",\"family\":\"\",\"size\":11.689497716895},\"tickangle\":-0,\"showline\":false,\"linecolor\":null,\"linewidth\":0,\"showgrid\":false,\"gridcolor\":null,\"gridwidth\":0,\"zeroline\":false,\"anchor\":\"x\",\"title\":{\"text\":\" Max Yield (kT of TNT)\",\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":14.6118721461187}},\"hoverformat\":\".2f\"},\"shapes\":[{\"type\":\"rect\",\"fillcolor\":null,\"line\":{\"color\":null,\"width\":0,\"linetype\":[]},\"yref\":\"paper\",\"xref\":\"paper\",\"x0\":0,\"x1\":1,\"y0\":0,\"y1\":1}],\"showlegend\":false,\"legend\":{\"bgcolor\":null,\"bordercolor\":null,\"borderwidth\":0,\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":11.689497716895}},\"hovermode\":\"closest\",\"barmode\":\"relative\"},\"config\":{\"doubleClick\":\"reset\",\"showSendToCloud\":false},\"source\":\"A\",\"attrs\":{\"1418cbc5a3a\":{\"x\":{},\"y\":{},\"colour\":{},\"type\":\"scatter\"}},\"cur_data\":\"1418cbc5a3a\",\"visdat\":{\"1418cbc5a3a\":[\"function (y) \",\"x\"]},\"highlight\":{\"on\":\"plotly_click\",\"persistent\":false,\"dynamic\":false,\"selectize\":false,\"opacityDim\":0.2,\"selected\":{\"opacity\":1},\"debounce\":0},\"shinyEvents\":[\"plotly_hover\",\"plotly_click\",\"plotly_selected\",\"plotly_relayout\",\"plotly_brushed\",\"plotly_brushing\",\"plotly_clickannotation\",\"plotly_doubleclick\",\"plotly_deselect\",\"plotly_afterplot\",\"plotly_sunburstclick\"],\"base_url\":\"https://plot.ly\"},\"evals\":[],\"jsHooks\":[]}\r\n6. How did methods of testing them change over time?\r\nWe focus on the 5 most common methods of testing out of a total 20. These 5 were: AIRDROP, ATMOSPH, SHAFT, SHAFT/GR, TUNNEL. AIRDROP is a device dropped from an aircraft and exploded in the atmosphere and ATMOSPH is also a method of testing performed above ground/water. SHAFT, SHAFT/GR, and TUNNEL are all underground methods of testing with their own different procedures.The results in how common they were over time are as follows.\r\n\r\n\r\n{\"x\":{\"data\":[{\"x\":[1945,1946,1951,1952,1953,1955,1956,1957,1958,1962,1965,1966,1967,1968,1969,1970,1972,1973,1974,1976],\"y\":[2,1,10,5,3,3,3,5,3,29,1,2,2,1,1,1,2,2,1,1],\"text\":[\"year: 1945<br />n:  2<br />type: AIRDROP\",\"year: 1946<br />n:  1<br />type: AIRDROP\",\"year: 1951<br />n: 10<br />type: AIRDROP\",\"year: 1952<br />n:  5<br />type: AIRDROP\",\"year: 1953<br />n:  3<br />type: AIRDROP\",\"year: 1955<br />n:  3<br />type: AIRDROP\",\"year: 1956<br />n:  3<br />type: AIRDROP\",\"year: 1957<br />n:  5<br />type: AIRDROP\",\"year: 1958<br />n:  3<br />type: AIRDROP\",\"year: 1962<br />n: 29<br />type: AIRDROP\",\"year: 1965<br />n:  1<br />type: AIRDROP\",\"year: 1966<br />n:  2<br />type: AIRDROP\",\"year: 1967<br />n:  2<br />type: AIRDROP\",\"year: 1968<br />n:  1<br />type: AIRDROP\",\"year: 1969<br />n:  1<br />type: AIRDROP\",\"year: 1970<br />n:  1<br />type: AIRDROP\",\"year: 1972<br />n:  2<br />type: AIRDROP\",\"year: 1973<br />n:  2<br />type: AIRDROP\",\"year: 1974<br />n:  1<br />type: AIRDROP\",\"year: 1976<br />n:  1<br />type: AIRDROP\"],\"type\":\"scatter\",\"mode\":\"lines\",\"line\":{\"width\":1.88976377952756,\"color\":\"rgba(68,1,84,1)\",\"dash\":\"solid\"},\"hoveron\":\"points\",\"name\":\"AIRDROP\",\"legendgroup\":\"AIRDROP\",\"showlegend\":true,\"xaxis\":\"x\",\"yaxis\":\"y\",\"hoverinfo\":\"text\",\"frame\":null},{\"x\":[1953,1954,1955,1956,1957,1958,1961,1962,1974,1976,1977,1978,1979,1980],\"y\":[5,7,2,5,13,34,48,63,1,2,1,2,1,1],\"text\":[\"year: 1953<br />n:  5<br />type: ATMOSPH\",\"year: 1954<br />n:  7<br />type: ATMOSPH\",\"year: 1955<br />n:  2<br />type: ATMOSPH\",\"year: 1956<br />n:  5<br />type: ATMOSPH\",\"year: 1957<br />n: 13<br />type: ATMOSPH\",\"year: 1958<br />n: 34<br />type: ATMOSPH\",\"year: 1961<br />n: 48<br />type: ATMOSPH\",\"year: 1962<br />n: 63<br />type: ATMOSPH\",\"year: 1974<br />n:  1<br />type: ATMOSPH\",\"year: 1976<br />n:  2<br />type: ATMOSPH\",\"year: 1977<br />n:  1<br />type: ATMOSPH\",\"year: 1978<br />n:  2<br />type: ATMOSPH\",\"year: 1979<br />n:  1<br />type: ATMOSPH\",\"year: 1980<br />n:  1<br />type: ATMOSPH\"],\"type\":\"scatter\",\"mode\":\"lines\",\"line\":{\"width\":1.88976377952756,\"color\":\"rgba(59,82,139,1)\",\"dash\":\"solid\"},\"hoveron\":\"points\",\"name\":\"ATMOSPH\",\"legendgroup\":\"ATMOSPH\",\"showlegend\":true,\"xaxis\":\"x\",\"yaxis\":\"y\",\"hoverinfo\":\"text\",\"frame\":null},{\"x\":[1957,1958,1961,1962,1963,1964,1965,1966,1967,1968,1969,1970,1971,1972,1973,1974,1975,1976,1977,1978,1979,1980,1981,1982,1983,1984,1985,1986,1987,1988,1989,1990,1991,1992],\"y\":[3,6,7,52,42,47,40,49,44,55,50,40,34,38,34,35,30,31,33,34,34,29,29,30,30,39,22,14,26,23,16,8,7,4],\"text\":[\"year: 1957<br />n:  3<br />type: SHAFT\",\"year: 1958<br />n:  6<br />type: SHAFT\",\"year: 1961<br />n:  7<br />type: SHAFT\",\"year: 1962<br />n: 52<br />type: SHAFT\",\"year: 1963<br />n: 42<br />type: SHAFT\",\"year: 1964<br />n: 47<br />type: SHAFT\",\"year: 1965<br />n: 40<br />type: SHAFT\",\"year: 1966<br />n: 49<br />type: SHAFT\",\"year: 1967<br />n: 44<br />type: SHAFT\",\"year: 1968<br />n: 55<br />type: SHAFT\",\"year: 1969<br />n: 50<br />type: SHAFT\",\"year: 1970<br />n: 40<br />type: SHAFT\",\"year: 1971<br />n: 34<br />type: SHAFT\",\"year: 1972<br />n: 38<br />type: SHAFT\",\"year: 1973<br />n: 34<br />type: SHAFT\",\"year: 1974<br />n: 35<br />type: SHAFT\",\"year: 1975<br />n: 30<br />type: SHAFT\",\"year: 1976<br />n: 31<br />type: SHAFT\",\"year: 1977<br />n: 33<br />type: SHAFT\",\"year: 1978<br />n: 34<br />type: SHAFT\",\"year: 1979<br />n: 34<br />type: SHAFT\",\"year: 1980<br />n: 29<br />type: SHAFT\",\"year: 1981<br />n: 29<br />type: SHAFT\",\"year: 1982<br />n: 30<br />type: SHAFT\",\"year: 1983<br />n: 30<br />type: SHAFT\",\"year: 1984<br />n: 39<br />type: SHAFT\",\"year: 1985<br />n: 22<br />type: SHAFT\",\"year: 1986<br />n: 14<br />type: SHAFT\",\"year: 1987<br />n: 26<br />type: SHAFT\",\"year: 1988<br />n: 23<br />type: SHAFT\",\"year: 1989<br />n: 16<br />type: SHAFT\",\"year: 1990<br />n:  8<br />type: SHAFT\",\"year: 1991<br />n:  7<br />type: SHAFT\",\"year: 1992<br />n:  4<br />type: SHAFT\"],\"type\":\"scatter\",\"mode\":\"lines\",\"line\":{\"width\":1.88976377952756,\"color\":\"rgba(33,144,140,1)\",\"dash\":\"solid\"},\"hoveron\":\"points\",\"name\":\"SHAFT\",\"legendgroup\":\"SHAFT\",\"showlegend\":true,\"xaxis\":\"x\",\"yaxis\":\"y\",\"hoverinfo\":\"text\",\"frame\":null},{\"x\":[1975,1976,1977,1978,1979,1980,1981,1982,1983,1984,1985,1986,1989],\"y\":[2,5,9,11,10,12,10,8,4,4,4,5,1],\"text\":[\"year: 1975<br />n:  2<br />type: SHAFT/GR\",\"year: 1976<br />n:  5<br />type: SHAFT/GR\",\"year: 1977<br />n:  9<br />type: SHAFT/GR\",\"year: 1978<br />n: 11<br />type: SHAFT/GR\",\"year: 1979<br />n: 10<br />type: SHAFT/GR\",\"year: 1980<br />n: 12<br />type: SHAFT/GR\",\"year: 1981<br />n: 10<br />type: SHAFT/GR\",\"year: 1982<br />n:  8<br />type: SHAFT/GR\",\"year: 1983<br />n:  4<br />type: SHAFT/GR\",\"year: 1984<br />n:  4<br />type: SHAFT/GR\",\"year: 1985<br />n:  4<br />type: SHAFT/GR\",\"year: 1986<br />n:  5<br />type: SHAFT/GR\",\"year: 1989<br />n:  1<br />type: SHAFT/GR\"],\"type\":\"scatter\",\"mode\":\"lines\",\"line\":{\"width\":1.88976377952756,\"color\":\"rgba(93,200,99,1)\",\"dash\":\"solid\"},\"hoveron\":\"points\",\"name\":\"SHAFT/GR\",\"legendgroup\":\"SHAFT/GR\",\"showlegend\":true,\"xaxis\":\"x\",\"yaxis\":\"y\",\"hoverinfo\":\"text\",\"frame\":null},{\"x\":[1957,1958,1961,1962,1963,1964,1965,1966,1967,1968,1969,1970,1971,1972,1973,1974,1975,1976,1977,1978,1979,1980,1981,1982,1983,1984,1985,1986,1987,1988,1989,1990,1991,1992],\"y\":[2,9,4,5,1,9,12,17,15,15,15,15,13,12,7,10,11,11,11,18,12,12,9,8,14,8,6,1,12,8,3,2,1,2],\"text\":[\"year: 1957<br />n:  2<br />type: TUNNEL\",\"year: 1958<br />n:  9<br />type: TUNNEL\",\"year: 1961<br />n:  4<br />type: TUNNEL\",\"year: 1962<br />n:  5<br />type: TUNNEL\",\"year: 1963<br />n:  1<br />type: TUNNEL\",\"year: 1964<br />n:  9<br />type: TUNNEL\",\"year: 1965<br />n: 12<br />type: TUNNEL\",\"year: 1966<br />n: 17<br />type: TUNNEL\",\"year: 1967<br />n: 15<br />type: TUNNEL\",\"year: 1968<br />n: 15<br />type: TUNNEL\",\"year: 1969<br />n: 15<br />type: TUNNEL\",\"year: 1970<br />n: 15<br />type: TUNNEL\",\"year: 1971<br />n: 13<br />type: TUNNEL\",\"year: 1972<br />n: 12<br />type: TUNNEL\",\"year: 1973<br />n:  7<br />type: TUNNEL\",\"year: 1974<br />n: 10<br />type: TUNNEL\",\"year: 1975<br />n: 11<br />type: TUNNEL\",\"year: 1976<br />n: 11<br />type: TUNNEL\",\"year: 1977<br />n: 11<br />type: TUNNEL\",\"year: 1978<br />n: 18<br />type: TUNNEL\",\"year: 1979<br />n: 12<br />type: TUNNEL\",\"year: 1980<br />n: 12<br />type: TUNNEL\",\"year: 1981<br />n:  9<br />type: TUNNEL\",\"year: 1982<br />n:  8<br />type: TUNNEL\",\"year: 1983<br />n: 14<br />type: TUNNEL\",\"year: 1984<br />n:  8<br />type: TUNNEL\",\"year: 1985<br />n:  6<br />type: TUNNEL\",\"year: 1986<br />n:  1<br />type: TUNNEL\",\"year: 1987<br />n: 12<br />type: TUNNEL\",\"year: 1988<br />n:  8<br />type: TUNNEL\",\"year: 1989<br />n:  3<br />type: TUNNEL\",\"year: 1990<br />n:  2<br />type: TUNNEL\",\"year: 1991<br />n:  1<br />type: TUNNEL\",\"year: 1992<br />n:  2<br />type: TUNNEL\"],\"type\":\"scatter\",\"mode\":\"lines\",\"line\":{\"width\":1.88976377952756,\"color\":\"rgba(253,231,37,1)\",\"dash\":\"solid\"},\"hoveron\":\"points\",\"name\":\"TUNNEL\",\"legendgroup\":\"TUNNEL\",\"showlegend\":true,\"xaxis\":\"x\",\"yaxis\":\"y\",\"hoverinfo\":\"text\",\"frame\":null}],\"layout\":{\"margin\":{\"t\":45.4063926940639,\"r\":7.30593607305936,\"b\":41.8264840182648,\"l\":37.2602739726027},\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":14.6118721461187},\"title\":{\"text\":\"Most common nuclear bomb testing methods over time\",\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":17.5342465753425},\"x\":0,\"xref\":\"paper\"},\"xaxis\":{\"domain\":[0,1],\"automargin\":true,\"type\":\"linear\",\"autorange\":false,\"range\":[1942.65,1994.35],\"tickmode\":\"array\",\"ticktext\":[\"1950\",\"1960\",\"1970\",\"1980\",\"1990\"],\"tickvals\":[1950,1960,1970,1980,1990],\"categoryorder\":\"array\",\"categoryarray\":[\"1950\",\"1960\",\"1970\",\"1980\",\"1990\"],\"nticks\":null,\"ticks\":\"\",\"tickcolor\":null,\"ticklen\":3.65296803652968,\"tickwidth\":0,\"showticklabels\":true,\"tickfont\":{\"color\":\"rgba(77,77,77,1)\",\"family\":\"\",\"size\":11.689497716895},\"tickangle\":-0,\"showline\":false,\"linecolor\":null,\"linewidth\":0,\"showgrid\":false,\"gridcolor\":null,\"gridwidth\":0,\"zeroline\":false,\"anchor\":\"y\",\"title\":{\"text\":\"year\",\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":14.6118721461187}},\"hoverformat\":\".2f\"},\"yaxis\":{\"domain\":[0,1],\"automargin\":true,\"type\":\"linear\",\"autorange\":false,\"range\":[-2.1,66.1],\"tickmode\":\"array\",\"ticktext\":[\"0\",\"20\",\"40\",\"60\"],\"tickvals\":[0,20,40,60],\"categoryorder\":\"array\",\"categoryarray\":[\"0\",\"20\",\"40\",\"60\"],\"nticks\":null,\"ticks\":\"\",\"tickcolor\":null,\"ticklen\":3.65296803652968,\"tickwidth\":0,\"showticklabels\":true,\"tickfont\":{\"color\":\"rgba(77,77,77,1)\",\"family\":\"\",\"size\":11.689497716895},\"tickangle\":-0,\"showline\":false,\"linecolor\":null,\"linewidth\":0,\"showgrid\":false,\"gridcolor\":null,\"gridwidth\":0,\"zeroline\":false,\"anchor\":\"x\",\"title\":{\"text\":\"n\",\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":14.6118721461187}},\"hoverformat\":\".2f\"},\"shapes\":[{\"type\":\"rect\",\"fillcolor\":null,\"line\":{\"color\":null,\"width\":0,\"linetype\":[]},\"yref\":\"paper\",\"xref\":\"paper\",\"x0\":0,\"x1\":1,\"y0\":0,\"y1\":1}],\"showlegend\":true,\"legend\":{\"bgcolor\":null,\"bordercolor\":null,\"borderwidth\":0,\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":11.689497716895},\"y\":1},\"hovermode\":\"closest\",\"barmode\":\"relative\"},\"config\":{\"doubleClick\":\"reset\",\"showSendToCloud\":false},\"source\":\"A\",\"attrs\":{\"14182a7522a9\":{\"x\":{},\"y\":{},\"colour\":{},\"type\":\"scatter\"}},\"cur_data\":\"14182a7522a9\",\"visdat\":{\"14182a7522a9\":[\"function (y) \",\"x\"]},\"highlight\":{\"on\":\"plotly_click\",\"persistent\":false,\"dynamic\":false,\"selectize\":false,\"opacityDim\":0.2,\"selected\":{\"opacity\":1},\"debounce\":0},\"shinyEvents\":[\"plotly_hover\",\"plotly_click\",\"plotly_selected\",\"plotly_relayout\",\"plotly_brushed\",\"plotly_brushing\",\"plotly_clickannotation\",\"plotly_doubleclick\",\"plotly_deselect\",\"plotly_afterplot\",\"plotly_sunburstclick\"],\"base_url\":\"https://plot.ly\"},\"evals\":[],\"jsHooks\":[]}\r\nIt is interesting to see that in the earlier days of testing ATMOSPH and AIRDROP - which are the two above ground/water methods of testing were the most popular. However, in the 1960’s and 1970’s these methods of testing plummeted and methods of testing that were underground became more common (sidenote: this was apparently to minimize any health hazards from radioactive dust and waste being blown far by the wind into populated areas.)\r\n7. Very simple application that lets you compare each countries nuclear detonation activity over time.\r\nLink to app.\r\n\r\n\r\n\r\n",
    "preview": "posts/2021-04-04-nuclearexplosions/nuclearexplosions_files/figure-html5/unnamed-chunk-6-1.png",
    "last_modified": "2021-04-04T00:33:40-05:00",
    "input_file": {}
  }
]
